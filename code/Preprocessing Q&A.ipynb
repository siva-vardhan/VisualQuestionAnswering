{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b160544me\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\b160544me\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\b160544me\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\b160544me\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\b160544me\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\b160544me\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os\n",
    "import collections\n",
    "import tensorflow as tf \n",
    "import re\n",
    "import h5py\n",
    "import argparse\n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Q/A module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "BUFFER_TOKENS = ['<NULL>', '<START>', '<END>', '<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_sentence(s):\n",
    "    s = s.replace('.', '')\n",
    "    s = s.replace(',', '')\n",
    "    s = s.replace('\"', '')\n",
    "    s = s.replace(\"'\", '')\n",
    "    s = s.replace(\"?\", '')\n",
    "    s = s.lower()\n",
    "    s = re.sub(\"\\s\\s+\", \" \", s)\n",
    "    s = s.split(' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_init_dic(filename):\n",
    "    df=pd.read_csv(filename,sep='|',header=None)\n",
    "    df=df[[0,1,2]]\n",
    "    df.columns = ['ImageNo', 'Question','Answer']\n",
    "    df.reset_index()\n",
    "    #bool_mat=[]\n",
    "    #for i in range(0,len(df)):\n",
    "    #    bool_mat.append(df['Question'].iloc[i][len(df['Question'].iloc[i])-1]=='?')\n",
    "    #df=df[bool_mat]\n",
    "    df['Q_parsed']=[ _parse_sentence(s) for s in df['Question']]\n",
    "    df['A_parsed']=[ _parse_sentence(s) for s in df['Answer']]\n",
    "    return df\n",
    "#Training Dataset\n",
    "dic_df=_create_init_dic(\"C:/Users/b160544me/Desktop/siva/project/dataset/VQAMed2019Training/QAPairsByCategory/C4_Abnormality_train.txt\")\n",
    "#Test Dataset\n",
    "dic_v_df=_create_init_dic(\"C:/Users/b160544me/Desktop/siva/project/dataset/VQAMed2019Validation/QAPairsByCategory/C4_Abnormality_val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3192, 5)\n",
      "(500, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(dic_df))\n",
    "print(np.shape(dic_v_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_words=[]\n",
    "for i in range(0,len(dic_df)):\n",
    "    list_of_all_words=list_of_all_words+dic_df['A_parsed'].iloc[i]+dic_df['Q_parsed'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter(list_of_all_words)\n",
    "TOTAL_VOCAB=len(counter)\n",
    "vocab = counter.most_common(TOTAL_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create word_to_idx, and idx_to_word\n",
    "vocab = [i[0] for i in vocab]\n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "# add in BUFFER_TOKENS\n",
    "for i in range(len(BUFFER_TOKENS)):\n",
    "    idx_to_word[int(i)] = BUFFER_TOKENS[i]\n",
    "    word_to_idx[BUFFER_TOKENS[i]] = i\n",
    "\n",
    "for i in range(len(vocab)):\n",
    "    word_to_idx[vocab[i]] = i + len(BUFFER_TOKENS)\n",
    "    idx_to_word[int(i + len(BUFFER_TOKENS))] = vocab[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(word_to_idx, open('C:/Users/b160544me/Desktop/siva/project/word_to_idx.pkl', 'wb') )\n",
    "pickle.dump(idx_to_word, open('C:/Users/b160544me/Desktop/siva/project/idx_to_word.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_LEN=22\n",
    "def _convert_sentence_to_numbers(s):\n",
    "    \"\"\"Convert a sentence s (a list of words) to list of numbers using word_to_idx\"\"\"\n",
    "    UNK_IDX = BUFFER_TOKENS.index('<UNK>')\n",
    "    NULL_IDX = BUFFER_TOKENS.index('<NULL>')\n",
    "    END_IDX = BUFFER_TOKENS.index('<END>')\n",
    "    STR_IDX = BUFFER_TOKENS.index('<START>')\n",
    "    s_encoded = [word_to_idx.get(w, UNK_IDX) for w in s]\n",
    "    s_encoded = [STR_IDX] + s_encoded\n",
    "    s_encoded += [END_IDX]\n",
    "    s_encoded += [NULL_IDX] * (PADDING_LEN - 1 - len(s_encoded))\n",
    "    return s_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "df_v_final=dic_v_df\n",
    "all_answers = [_convert_sentence_to_numbers(s) for s in np.array(df_v_final['A_parsed'])] # list of numbers \n",
    "print(len(all_answers))\n",
    "for i in range(len(all_answers)):\n",
    "    if(len(all_answers[i])!=PADDING_LEN-1):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=dic_df\n",
    "all_answers = [_convert_sentence_to_numbers(s) for s in np.array(df_final['A_parsed'])] # list of numbers \n",
    "valid_rows1 = [i for i in range(len(all_answers)) if len(all_answers[i]) == PADDING_LEN-1]\n",
    "df_final=df_final.iloc[valid_rows1,:]\n",
    "df_final['A_Encoded']=[row for row in all_answers if len(row) == PADDING_LEN-1]\n",
    "all_questions = [_convert_sentence_to_numbers(s) for s in np.array(df_final['Q_parsed'])] \n",
    "valid_rows2 = [i for i in range(len(all_questions)) if len(all_questions[i]) == PADDING_LEN-1]\n",
    "df_final=df_final.iloc[valid_rows2,:]\n",
    "df_final['Q_Encoded']=[row for row in all_questions if len(row) == PADDING_LEN-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v_final=dic_v_df\n",
    "all_answers = [_convert_sentence_to_numbers(s) for s in np.array(df_v_final['A_parsed'])] # list of numbers \n",
    "valid_rows3 = [i for i in range(len(all_answers)) if len(all_answers[i]) == PADDING_LEN-1]\n",
    "df_v_final=df_v_final.iloc[valid_rows3,:]\n",
    "df_v_final['A_Encoded']=[row for row in all_answers if len(row) == PADDING_LEN-1]\n",
    "all_questions = [_convert_sentence_to_numbers(s) for s in np.array(df_v_final['Q_parsed'])] \n",
    "valid_rows4 = [i for i in range(len(all_questions)) if len(all_questions[i]) == PADDING_LEN-1]\n",
    "df_v_final=df_v_final.iloc[valid_rows4,:]\n",
    "df_v_final['Q_Encoded']=[row for row in all_questions if len(row) == PADDING_LEN-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3192, 5)\n",
      "(500, 5)\n",
      "(3192,)\n",
      "(3192,)\n",
      "(500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(dic_df))\n",
    "print(np.shape(dic_v_df))\n",
    "print(np.shape(valid_rows1))\n",
    "print(np.shape(valid_rows2))\n",
    "print(np.shape(valid_rows3))\n",
    "print(np.shape(valid_rows4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageNo</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Q_parsed</th>\n",
       "      <th>A_parsed</th>\n",
       "      <th>A_Encoded</th>\n",
       "      <th>Q_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>synpic54733</td>\n",
       "      <td>what is the primary abnormality in this image?</td>\n",
       "      <td>paraganglioma</td>\n",
       "      <td>[what, is, the, primary, abnormality, in, this...</td>\n",
       "      <td>[paraganglioma]</td>\n",
       "      <td>[1, 439, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1, 5, 4, 6, 16, 10, 7, 9, 8, 2, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>synpic25647</td>\n",
       "      <td>is there an abnormality in the x-ray?</td>\n",
       "      <td>no</td>\n",
       "      <td>[is, there, an, abnormality, in, the, x-ray]</td>\n",
       "      <td>[no]</td>\n",
       "      <td>[1, 46, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 4, 44, 133, 10, 7, 6, 21, 2, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>synpic35681</td>\n",
       "      <td>is there an abnormality in the mri?</td>\n",
       "      <td>no</td>\n",
       "      <td>[is, there, an, abnormality, in, the, mri]</td>\n",
       "      <td>[no]</td>\n",
       "      <td>[1, 46, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 4, 44, 133, 10, 7, 6, 17, 2, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>synpic39641</td>\n",
       "      <td>what is the primary abnormality in this image?</td>\n",
       "      <td>ganglion cyst</td>\n",
       "      <td>[what, is, the, primary, abnormality, in, this...</td>\n",
       "      <td>[ganglion, cyst]</td>\n",
       "      <td>[1, 1630, 24, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 5, 4, 6, 16, 10, 7, 9, 8, 2, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>synpic35693</td>\n",
       "      <td>is this a normal mri?</td>\n",
       "      <td>yes</td>\n",
       "      <td>[is, this, a, normal, mri]</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>[1, 39, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 4, 9, 72, 38, 17, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageNo                                        Question         Answer  \\\n",
       "0  synpic54733  what is the primary abnormality in this image?  paraganglioma   \n",
       "1  synpic25647           is there an abnormality in the x-ray?             no   \n",
       "2  synpic35681             is there an abnormality in the mri?             no   \n",
       "3  synpic39641  what is the primary abnormality in this image?  ganglion cyst   \n",
       "4  synpic35693                           is this a normal mri?            yes   \n",
       "\n",
       "                                            Q_parsed          A_parsed  \\\n",
       "0  [what, is, the, primary, abnormality, in, this...   [paraganglioma]   \n",
       "1       [is, there, an, abnormality, in, the, x-ray]              [no]   \n",
       "2         [is, there, an, abnormality, in, the, mri]              [no]   \n",
       "3  [what, is, the, primary, abnormality, in, this...  [ganglion, cyst]   \n",
       "4                         [is, this, a, normal, mri]             [yes]   \n",
       "\n",
       "                                           A_Encoded  \\\n",
       "0  [1, 439, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1  [1, 46, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [1, 46, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3  [1, 1630, 24, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [1, 39, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                           Q_Encoded  \n",
       "0  [1, 5, 4, 6, 16, 10, 7, 9, 8, 2, 0, 0, 0, 0, 0...  \n",
       "1  [1, 4, 44, 133, 10, 7, 6, 21, 2, 0, 0, 0, 0, 0...  \n",
       "2  [1, 4, 44, 133, 10, 7, 6, 17, 2, 0, 0, 0, 0, 0...  \n",
       "3  [1, 5, 4, 6, 16, 10, 7, 9, 8, 2, 0, 0, 0, 0, 0...  \n",
       "4  [1, 4, 9, 72, 38, 17, 2, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save preprocessed training data frame\n",
    "df_final.to_pickle(\"C:/Users/b160544me/Desktop/siva/project/train_df_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save preprocessed test data frame\n",
    "df_v_final.to_pickle(\"C:/Users/b160544me/Desktop/siva/project/test_df_v_final.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take input as preprocssed images (features) and select valid rows based on above selection during training\n",
    "file = open('C:/Users/b160544me/Desktop/siva/project/image_feature_train.pkl', 'rb')\n",
    "features = pickle.load(file)\n",
    "features = np.array(features)\n",
    "features = features[valid_rows1,]\n",
    "features = features[valid_rows2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(features, open('C:/Users/b160544me/Desktop/siva/project/image_feature_train.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take input as preprocssed images (features) and select valid rows based on above selection during testing\n",
    "file = open('C:/Users/b160544me/Desktop/siva/project/image_feature_test.pkl', 'rb')\n",
    "features = pickle.load(file)\n",
    "features = np.array(features)\n",
    "features = features[valid_rows3,]\n",
    "features = features[valid_rows4,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(features, open('C:/Users/b160544me/Desktop/siva/project/image_feature_test.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
